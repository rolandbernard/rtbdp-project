
\section{Lessons Learned} \label{leasons}

This section concludes the report by discussing what has worked well in the project, what were some of the main challenges, and what future improvements could be made to the system.

\subsection{Successes}

Overall, the architecture proved robust for the defined use case. The combination of Kafka and Flink handled the throughput of the GitHub API relatively well, even on somewhat older hardware. The use of Docker Compose significantly simplified the deployment process, by making the complex distributed system reproducible on different machines. The integration of TimescaleDB allowed for efficient storage and querying of historical time-series data without the operational overhead of managing a separate time-series database. The resulting dashboard provides a window into the development activity of the open-source world.

\subsection{Challenges}

Even with these successes, the project still faced some challenges.

\paragraph{Real-Time Ranking}
Generating a global leaderboard that updates in real-time was non-trivial. The main difficulty arises from the fact that a large number of ranks can change quickly. For example, if a repository jumps up in the ranking, all rows below may also be moved. Achieving this efficiently required tight coordination between the ranking process in Flink, the view based optimizations in the database, and the ability of the frontend to handle ranking updates in a specialized way.

\paragraph{High-Frequency Updates for Long Windows}
Standard Flink windowing proved inefficient for maintaining sliding windows that are very long, e.g., 24 hours, but are updated very frequently, e.g., every 1 second. This necessitated the implementation of a custom \inlinecode{KeyedProcessFunction} to optimize state management and triggering.

\paragraph{API Changes}
During the development lifecycle, specifically around October, GitHub modified their API payload, removing certain details. This caused the processing to crash, requiring refactoring of some parts of the parsing and transformation logic in the Flink processor.

\paragraph{Debugging Flink}
Gaining sufficient visibility into the internal state of Flink operators during streaming execution was difficult. This made it difficult to diagnose logic errors in the complex windowing functions and ranking logic. Further, there was a problem with state continually growing in size that was hard to debug due to Flink's limited facilities of inspecting state.

\subsection{Potential Improvements}

The project also features multiple potential avenues for future improvements. Aside from adding additional charts using the existing analysis results, the following may be promising additions.

\paragraph{Enhanced Trending Algorithm}
The current trending score is a linear combination of star counts and as such very simplistic. A more sophisticated model could incorporate the acceleration of stars or social signals such as created issues, pull requests, or comments. This could help to identify trending repositories earlier.

\paragraph{Data Enrichment}
Integrating additional data sources, such as tracking mentions of repositories on social media such as X or Reddit, would also provide a more comprehensive view of the trending status of repositories. This information could be useful both to identify which repositories are trending but also possibly give insights into why they are trending, something that is currently obscured in the system.

\paragraph{Sentiment Analysis}
Finally, analyzing the text content of some types of the events, such as commit messages, issue descriptions, and pull request comments could provide qualitative insights into the sentiment of different developer communities.
